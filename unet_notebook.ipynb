{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\"\"\"\n",
    "PyTorchUNet model script.\n",
    "\n",
    "This script defines the UNet architecture in PyTorch, which is used for image segmentation tasks.\n",
    "\n",
    "Classes:\n",
    "    DoubleConvBlock: A convolutional block in the UNet architecture.\n",
    "    UNet: The full UNet model.\n",
    "\n",
    "(c) 2023 Bhimraj Yadav. All rights reserved.\n",
    "\"\"\"\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    \"\"\" A convolutional block in the UNet architecture.\n",
    "\n",
    "    This block consists of two convolutional layers with batch normalization followed by a ReLU \n",
    "    activation function.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): The number of input channels.\n",
    "        out_channels (int): The number of output channels.\n",
    "        kernel_size (int): The size of the convolutional kernel.\n",
    "        padding (int): The padding to be applied to the input.\n",
    "\n",
    "    Attributes:\n",
    "        conv1 (nn.Conv2d): The first convolutional layer.\n",
    "        conv2 (nn.Conv2d): The second convolutional layer.\n",
    "        batchnorm (nn.BatchNorm2d): The batch normalization layer.\n",
    "        relu (nn.ReLU): The ReLU activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        padding: int = 1,\n",
    "    ):\n",
    "        \"\"\"Initializes DoubleConvBlock with specified input and output channels, kernel size, and padding.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): The number of input channels.\n",
    "            out_channels (int): The number of output channels.\n",
    "            kernel_size (int, optional): The size of the convolutional kernel. Defaults to 3.\n",
    "            padding (int, optional): The padding to be applied to the input. Defaults to 1.\n",
    "        \"\"\"\n",
    "        super(DoubleConvBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "        )\n",
    "        self.batchnorm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "        )\n",
    "        self.batchnorm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the convolutional block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"The encoder part of the UNet architecture.\n",
    "\n",
    "    This consists of a series of convolutional blocks followed by maxpooling operations\n",
    "    with increasing number of channels.\n",
    "\n",
    "    Args:\n",
    "        channels (List[int]): A list of channels for convolutionals block.\n",
    "\n",
    "    Attributes:\n",
    "        encoder_blocks (nn.ModuleList): A list of convolutional blocks followed by maxpooling.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: List[int]) -> None:\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_blocks = nn.ModuleList()\n",
    "\n",
    "        # Add a convolutional block followed by maxpooling(except last one) for each channel\n",
    "        for i in range(len(channels)-1):\n",
    "            self.encoder_blocks.append(DoubleConvBlock(channels[i], channels[i+1])),\n",
    "\n",
    "            # Add a max pooling layer after each convolutional block except the last one\n",
    "            if i < len(channels)-2:\n",
    "                self.encoder_blocks.append(nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"Forward pass of the encoder.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            List[torch.Tensor]: A list of tensors from each encoder block.\n",
    "        \"\"\"\n",
    "        encoder_features = []\n",
    "        for encoder_block in self.encoder_blocks:\n",
    "            x = encoder_block(x)\n",
    "\n",
    "            # Save the output of each convolutional block\n",
    "            if isinstance(encoder_block, DoubleConvBlock):\n",
    "                encoder_features.append(x)\n",
    "\n",
    "        return encoder_features\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The decoder part of the UNet architecture.\n",
    "\n",
    "    This consists of a series of convolutional blocks with decreasing number of channels.\n",
    "\n",
    "    Args:\n",
    "        channels (List[int]): A list of channels for convolutionals block.\n",
    "\n",
    "    Attributes:\n",
    "        decoder_blocks (nn.ModuleList): A list of convolutional blocks.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: List[int]) -> None:\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "\n",
    "        # Add a upconvolutional block followed by a convolutional block for each channel\n",
    "        for i in range(len(channels)-1):\n",
    "            self.decoder_blocks.append(nn.ConvTranspose2d(\n",
    "                channels[i], channels[i+1], 2, 2))\n",
    "            self.decoder_blocks.append(DoubleConvBlock(channels[i], channels[i+1]))\n",
    "\n",
    "    def _center_crop(self, feature: torch.Tensor, target_size: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Crops the input tensor to the target size.\n",
    "\n",
    "        Args:\n",
    "            feature (torch.Tensor): The input tensor.\n",
    "            target_size (torch.Tensor): The target size.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The cropped tensor.\n",
    "        \"\"\"\n",
    "        _, _, H, W = target_size.shape\n",
    "        _, _, h, w = feature.shape\n",
    "\n",
    "        # Calculate the starting indices for the crop\n",
    "        h_start = (h - H) // 2\n",
    "        w_start = (w - W) // 2\n",
    "\n",
    "        # Crop and returns the tensor\n",
    "        return feature[:, :, h_start:h_start+H, w_start:w_start+W]\n",
    "\n",
    "    def forward(self, x: torch.Tensor, encoder_features: List[torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the decoder.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "            encoder_features (List[torch.Tensor]): A list of tensors from each encoder block.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        for i, decoder_block in enumerate(self.decoder_blocks):\n",
    "\n",
    "            # Concatenate the output of the encoder with the output of the decoder\n",
    "            if isinstance(decoder_block, DoubleConvBlock):\n",
    "                encoder_feature = self._center_crop(encoder_features[i//2], x)\n",
    "                x = torch.cat([x, encoder_feature], dim=1)\n",
    "\n",
    "            # Apply the upconv or convolutional block\n",
    "            x = decoder_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"The UNet architecture.   \n",
    "\n",
    "    Args:\n",
    "        out_channels (int): The number of output channels.\n",
    "        channels (List[int]): A list of channels for convolutionals block.\n",
    "\n",
    "    Attributes:\n",
    "        encoder (Encoder): The encoder part of the UNet architecture.\n",
    "        decoder (Decoder): The decoder part of the UNet architecture.\n",
    "        output (nn.Conv2d): The output layer.\n",
    "\n",
    "    Example:\n",
    "        >>> model = UNet(channels=[3, 64, 128, 256, 512], out_channels=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: List[int],\n",
    "        out_channels: int,\n",
    "    ) -> None:\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = Encoder(channels)\n",
    "        self.decoder = Decoder(channels[::-1][:-1])\n",
    "        self.output = nn.Conv2d(channels[1], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the UNet architecture.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor.\n",
    "        \"\"\"\n",
    "        encoder_features = self.encoder(x)[::-1]\n",
    "        x = self.decoder(encoder_features[0], encoder_features[1:])\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    model = UNet(channels=[3, 64, 128, 256, 512], out_channels=1)\n",
    "\n",
    "    # Test the model\n",
    "    x = torch.randn(1, 3, 572, 572)\n",
    "    y = model(x)\n",
    "    print(y.shape)\n",
    "\n",
    "    # Save the model\n",
    "    # torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(channels=[3, 64, 128, 256, 512], out_channels=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
      "              ReLU-3         [-1, 64, 256, 256]               0\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
      "              ReLU-6         [-1, 64, 256, 256]               0\n",
      "         ConvBlock-7         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
      "             ReLU-11        [-1, 128, 128, 128]               0\n",
      "           Conv2d-12        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
      "             ReLU-14        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-15        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-16          [-1, 128, 64, 64]               0\n",
      "           Conv2d-17          [-1, 256, 64, 64]         295,168\n",
      "      BatchNorm2d-18          [-1, 256, 64, 64]             512\n",
      "             ReLU-19          [-1, 256, 64, 64]               0\n",
      "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-21          [-1, 256, 64, 64]             512\n",
      "             ReLU-22          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-23          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-24          [-1, 256, 32, 32]               0\n",
      "           Conv2d-25          [-1, 512, 32, 32]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-27          [-1, 512, 32, 32]               0\n",
      "           Conv2d-28          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-30          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-31          [-1, 512, 32, 32]               0\n",
      "          Encoder-32  [[-1, 64, 256, 256], [-1, 128, 128, 128], [-1, 256, 64, 64], [-1, 512, 32, 32]]               0\n",
      "  ConvTranspose2d-33          [-1, 256, 64, 64]         524,544\n",
      "           Conv2d-34          [-1, 256, 64, 64]       1,179,904\n",
      "      BatchNorm2d-35          [-1, 256, 64, 64]             512\n",
      "             ReLU-36          [-1, 256, 64, 64]               0\n",
      "           Conv2d-37          [-1, 256, 64, 64]         590,080\n",
      "      BatchNorm2d-38          [-1, 256, 64, 64]             512\n",
      "             ReLU-39          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-40          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-41        [-1, 128, 128, 128]         131,200\n",
      "           Conv2d-42        [-1, 128, 128, 128]         295,040\n",
      "      BatchNorm2d-43        [-1, 128, 128, 128]             256\n",
      "             ReLU-44        [-1, 128, 128, 128]               0\n",
      "           Conv2d-45        [-1, 128, 128, 128]         147,584\n",
      "      BatchNorm2d-46        [-1, 128, 128, 128]             256\n",
      "             ReLU-47        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-48        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-49         [-1, 64, 256, 256]          32,832\n",
      "           Conv2d-50         [-1, 64, 256, 256]          73,792\n",
      "      BatchNorm2d-51         [-1, 64, 256, 256]             128\n",
      "             ReLU-52         [-1, 64, 256, 256]               0\n",
      "           Conv2d-53         [-1, 64, 256, 256]          36,928\n",
      "      BatchNorm2d-54         [-1, 64, 256, 256]             128\n",
      "             ReLU-55         [-1, 64, 256, 256]               0\n",
      "        ConvBlock-56         [-1, 64, 256, 256]               0\n",
      "          Decoder-57         [-1, 64, 256, 256]               0\n",
      "           Conv2d-58          [-1, 1, 256, 256]              65\n",
      "================================================================\n",
      "Total params: 7,702,977\n",
      "Trainable params: 7,702,977\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 914.50\n",
      "Params size (MB): 29.38\n",
      "Estimated Total Size (MB): 944.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 256, 256))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
